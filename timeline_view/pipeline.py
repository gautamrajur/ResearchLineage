"""
pipeline.py - Main orchestrator for the timeline pipeline

Wires together:
    semantic_scholar.py ‚Üí text_extraction.py ‚Üí gemini_analysis.py

Flow per step:
    1. get_paper() ‚Üí paper details
    2. get_references() ‚Üí all references
    3. filter_methodology_references() ‚Üí top candidates
    4. extract_paper_text() ‚Üí text for target + each candidate
    5. analyze_step() ‚Üí Gemini selects predecessor + analyzes + compares
    6. Save step data + training example
    7. Predecessor becomes new target ‚Üí repeat

Stops when:
    - No methodology references found (foundational paper)
    - Max depth reached
    - Paper already visited (cycle detection)
"""

import time

from config import MAX_DEPTH, VERBOSE
from semantic_scholar import (
    get_paper, get_references,
    filter_methodology_references, get_arxiv_id
)
from text_extraction import extract_paper_text
from gemini_analysis import (
    analyze_step, analyze_foundational,
    MAIN_PROMPT, FOUNDATIONAL_PROMPT
)
from data_export import save_training_example, save_timeline_json


# ========================================
# Main Pipeline
# ========================================

def build_timeline(paper_id, max_depth=MAX_DEPTH):
    """
    Build complete research lineage timeline for a paper.

    Args:
        paper_id: arXiv URL, arXiv ID, or S2 paper ID

    Returns:
        list: Timeline steps from target (depth 0) to oldest ancestor.
              Each step is a dict:
              {
                  "depth": int,
                  "target_paper": {paperId, title, year, abstract, ...},
                  "target_text": str (formatted text sent to Gemini),
                  "target_source_type": "FULL_TEXT" or "ABSTRACT_ONLY",
                  "predecessor_paper": {paperId, title, year, ...} or None,
                  "candidates_considered": int,
                  "analysis": {Gemini output dict},
                  "is_foundational": bool
              }
    """
    timeline_steps = []
    current_paper_id = paper_id
    visited = set()
    original_target_info = None
    lineage_chain = []  # Track full chain of paper IDs

    _print_header("BUILDING RESEARCH LINEAGE TIMELINE")

    for depth in range(max_depth):
        _print_step_header(depth, max_depth)

        # --- Cycle detection ---
        if current_paper_id in visited:
            if VERBOSE:
                print(f"  ‚ö†Ô∏è  Already visited {current_paper_id}. Stopping.")
            break
        visited.add(current_paper_id)

        # --- 1. Fetch target paper ---
        if VERBOSE:
            print(f"\n  1Ô∏è‚É£  Fetching paper details...")
        target_paper = get_paper(current_paper_id)
        if not target_paper:
            if VERBOSE:
                print(f"  ‚ùå Could not fetch paper. Stopping.")
            break

        # Track original target paper info for domain consistency
        if original_target_info is None:
            abstract = target_paper.get("abstract", "")
            title = target_paper.get("title", "")
            # Ask Gemini to infer domain would cost tokens ‚Äî just use title + first sentence of abstract
            domain_hint = f"{title}. {abstract[:200] if abstract else ''}"
            original_target_info = {
                "title": title,
                "domain": domain_hint
            }

        # --- 2. Extract target paper text ---
        if VERBOSE:
            print(f"\n  2Ô∏è‚É£  Extracting target paper text...")
        target_text, target_source = extract_paper_text(target_paper)
        if VERBOSE:
            print(f"    Source: {target_source} "
                  f"(~{len(target_text) // 4:,} tokens)")

        # --- 3. Fetch references ---
        if VERBOSE:
            print(f"\n  3Ô∏è‚É£  Fetching references...")
        references = get_references(current_paper_id)

        # --- 4. Filter methodology references ---
        if VERBOSE:
            print(f"\n  4Ô∏è‚É£  Filtering methodology references...")
        candidates = filter_methodology_references(references) if references else []

        # --- No candidates = foundational paper ---
        if not candidates:
            if VERBOSE:
                print(f"\n  üìç No methodology candidates found.")
                print(f"     This is a FOUNDATIONAL paper. Running final analysis...")

            step = _handle_foundational_paper(
                depth, target_paper, target_text, target_source
            )
            if step:
                timeline_steps.append(step)
            break

        # --- 5. Extract text for all candidates ---
        if VERBOSE:
            print(f"\n  5Ô∏è‚É£  Extracting text for {len(candidates)} candidates...")
        candidates_with_text = _extract_candidate_texts(candidates)

        # --- 6. Call Gemini ---
        if VERBOSE:
            print(f"\n  6Ô∏è‚É£  Calling Gemini for analysis...")
        analysis, prompt_text, raw_response = analyze_step(
            target_text, candidates_with_text, original_target_info
        )
        if not analysis:
            if VERBOSE:
                print(f"  ‚ùå Gemini analysis failed. Stopping.")
            break

        # --- 7. Find selected predecessor ---
        selected_id = analysis.get("selected_predecessor_id")

        # Gemini might return null if no same-domain predecessor found
        if not selected_id or selected_id == "null":
            if VERBOSE:
                print(f"\n  üìç Gemini found no same-domain predecessor.")
                print(f"     Treating current paper as foundational...")
            step = _handle_foundational_paper(
                depth, target_paper, target_text, target_source
            )
            if step:
                # Merge the existing analysis into foundational step
                step["analysis"]["target_analysis"] = analysis.get("target_analysis", step["analysis"].get("target_analysis", {}))
                timeline_steps.append(step)
            break

        predecessor_paper = _find_predecessor(selected_id, candidates)

        if not predecessor_paper:
            if VERBOSE:
                print(f"  ‚ùå Selected predecessor not found in candidates. Stopping.")
            break

        if VERBOSE:
            print(f"\n  ‚úÖ PREDECESSOR SELECTED:")
            print(f"     {predecessor_paper.get('title', '?')} "
                  f"({predecessor_paper.get('year', '?')})")
            print(f"     Reason: {analysis.get('selection_reasoning', 'N/A')[:100]}...")

        # --- 8. Save step ---
        lineage_chain.append(target_paper.get("paperId"))

        step = {
            "depth": depth,
            "target_paper": target_paper,
            "target_text": target_text,
            "target_source_type": target_source,
            "predecessor_paper": predecessor_paper,
            "candidates_considered": len(candidates),
            "analysis": analysis,
            "is_foundational": False
        }
        timeline_steps.append(step)

        # --- 9. Save training example ---
        save_training_example(
            paper_id=target_paper["paperId"],
            instruction=MAIN_PROMPT,
            prompt_text=prompt_text,
            response_text=raw_response,
            metadata={
                "target_paper_id": target_paper["paperId"],
                "target_title": target_paper.get("title"),
                "predecessor_paper_id": predecessor_paper["paperId"],
                "depth": depth,
                "candidates_considered": len(candidates),
                "target_source_type": target_source,
                "model": "gemini-2.5-pro",
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
            },
            target_paper=target_paper,
            candidates=[c for c in candidates],
            predecessor_paper=predecessor_paper,
            lineage_chain=list(lineage_chain)
        )

        # --- 10. Move to predecessor ---
        current_paper_id = predecessor_paper["paperId"]

        if VERBOSE:
            print(f"\n  ‚û°Ô∏è  Moving to predecessor for next step...")
        time.sleep(1)

    # --- Check if we need to analyze the last predecessor ---
    # The last predecessor never became a target, so it has no analysis yet.
    # Unless we already handled it as foundational above.
    if timeline_steps and not timeline_steps[-1]["is_foundational"]:
        last_predecessor = timeline_steps[-1]["predecessor_paper"]

        # Check if this predecessor has methodology references
        if VERBOSE:
            print(f"\n  üîç Checking if last predecessor needs foundational analysis...")
        last_refs = get_references(last_predecessor["paperId"])
        last_candidates = filter_methodology_references(last_refs) if last_refs else []

        if not last_candidates:
            # It's foundational ‚Äî analyze it
            if VERBOSE:
                print(f"  üìç Last predecessor is foundational. Analyzing...")
            last_text, last_source = extract_paper_text(last_predecessor)
            last_step = _handle_foundational_paper(
                len(timeline_steps), last_predecessor, last_text, last_source
            )
            if last_step:
                timeline_steps.append(last_step)

    _print_summary(timeline_steps)

    return timeline_steps


# ========================================
# Helper Functions
# ========================================

def _handle_foundational_paper(depth, paper, paper_text, source_type):
    """
    Run foundational analysis for the last paper in chain.

    Returns:
        dict: Step data or None on failure
    """
    analysis, prompt_text, raw_response = analyze_foundational(paper_text)
    if not analysis:
        if VERBOSE:
            print(f"  ‚ùå Foundational analysis failed.")
        return None

    if VERBOSE:
        bt = analysis.get("target_analysis", {}).get("breakthrough_level", "?")
        print(f"  ‚úÖ Foundational paper analyzed (breakthrough: {bt})")

    # Save training example
    save_training_example(
        paper_id=paper["paperId"],
        instruction=FOUNDATIONAL_PROMPT,
        prompt_text=prompt_text,
        response_text=raw_response,
        metadata={
            "target_paper_id": paper["paperId"],
            "target_title": paper.get("title"),
            "predecessor_paper_id": None,
            "depth": depth,
            "candidates_considered": 0,
            "target_source_type": source_type,
            "is_foundational": True,
            "model": "gemini-2.5-pro",
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
        },
        target_paper=paper,
        candidates=None,
        predecessor_paper=None,
        lineage_chain=None
    )

    return {
        "depth": depth,
        "target_paper": paper,
        "target_text": paper_text,
        "target_source_type": source_type,
        "predecessor_paper": None,
        "candidates_considered": 0,
        "analysis": analysis,
        "is_foundational": True
    }


def _extract_candidate_texts(candidates):
    """
    Extract text for each candidate paper.

    Args:
        candidates: List from filter_methodology_references()

    Returns:
        list of tuples: (paper_data, text, source_type, contexts)
    """
    results = []
    for c in candidates:
        paper = c["paper"]
        text, source_type = extract_paper_text(paper)
        results.append((paper, text, source_type, c["contexts"]))
    return results


def _find_predecessor(selected_id, candidates):
    """
    Find the selected predecessor in the candidate list.

    Args:
        selected_id: paperId string from Gemini output
        candidates: List from filter_methodology_references()

    Returns:
        dict: Paper data or None
    """
    if not selected_id:
        return None

    for c in candidates:
        if c["paper"].get("paperId") == selected_id:
            return c["paper"]

    # Gemini might have returned a slightly different ID format
    # Try matching by title as fallback
    if VERBOSE:
        print(f"  ‚ö†Ô∏è  Exact ID match failed for {selected_id}. "
              f"Trying first candidate as fallback...")
    if candidates:
        return candidates[0]["paper"]

    return None


# ========================================
# Display
# ========================================

def display_timeline(timeline_steps):
    """
    Pretty-print the timeline from oldest to newest.

    Args:
        timeline_steps: List from build_timeline()
    """
    if not timeline_steps:
        print("No timeline data to display.")
        return

    # Build ordered list: oldest (foundational) ‚Üí newest (target)
    papers = []

    # Walk backwards through steps
    for step in reversed(timeline_steps):
        analysis = step["analysis"]
        target = step["target_paper"]
        ta = analysis.get("target_analysis", {})

        papers.append({
            "title": target.get("title", "?"),
            "year": target.get("year", "?"),
            "analysis": ta,
            "comparison": analysis.get("comparison"),
            "is_foundational": step["is_foundational"],
            "depth": step["depth"]
        })

    print(f"\n{'=' * 70}")
    print(f"üìÖ RESEARCH LINEAGE TIMELINE")
    print(f"{'=' * 70}\n")

    for i, paper in enumerate(papers):
        year = paper["year"]
        title = paper["title"]
        ta = paper["analysis"]

        # Breakthrough icon
        bt = ta.get("breakthrough_level", "minor")
        icon = {
            "revolutionary": "üî•",
            "major": "‚ö°",
            "moderate": "üí°",
            "minor": "‚óã"
        }.get(bt, "‚óã")

        # Markers
        markers = []
        if i == len(papers) - 1:
            markers.append("üéØ TARGET")
        if paper["is_foundational"]:
            markers.append("üèõÔ∏è FOUNDATION")
        marker_str = " ".join(markers)

        print(f"  {year} ‚îÄ‚îÄ {title}")
        print(f"         {icon} {bt.upper()} {marker_str}")
        print(f"         üìå {ta.get('key_innovation', 'N/A')[:80]}")

        # Show comparison (how this improved upon previous)
        comp = paper.get("comparison")
        if comp:
            print(f"         ‚¨ÜÔ∏è  Improved: {comp.get('what_was_improved', 'N/A')[:80]}")

        print()

        # Arrow to next paper
        if i < len(papers) - 1:
            print(f"         ‚îÇ")
            print(f"         ‚ñº")
            print()

    print(f"{'=' * 70}")
    print(f"  Papers in lineage: {len(papers)}")
    first_year = papers[0]["year"] if papers else "?"
    last_year = papers[-1]["year"] if papers else "?"
    print(f"  Time span: {first_year} ‚Üí {last_year}")
    print(f"{'=' * 70}")


# ========================================
# Print Helpers
# ========================================

def _print_header(text):
    if VERBOSE:
        print(f"\n{'=' * 60}")
        print(f"üî¨ {text}")
        print(f"{'=' * 60}")


def _print_step_header(depth, max_depth):
    if VERBOSE:
        print(f"\n{'‚îÄ' * 50}")
        print(f"üìç STEP {depth + 1} / {max_depth}")
        print(f"{'‚îÄ' * 50}")


def _print_summary(timeline_steps):
    if VERBOSE:
        print(f"\n{'=' * 60}")
        print(f"‚úÖ TIMELINE COMPLETE: {len(timeline_steps)} papers traced")

        total_cost = 0
        for step in timeline_steps:
            tokens = len(step.get("target_text", "")) // 4
            total_cost += (tokens / 1_000_000) * 1.25

        print(f"   Estimated total cost: ${total_cost:.3f}")
        print(f"{'=' * 60}")


# ========================================
# Test
# ========================================

if __name__ == "__main__":
    print("Testing Pipeline with 'Attention Is All You Need'")
    print("=" * 60)

    # Run the pipeline
    timeline = build_timeline("1706.03762", max_depth=6)

    # Display results
    display_timeline(timeline)

    # Save results
    save_timeline_json(timeline, "transformer_timeline.json")

    print("\n‚úÖ Pipeline test complete!")